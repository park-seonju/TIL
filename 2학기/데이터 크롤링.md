### 인터넷에서 데이터를 수집하는 방법

- OpenAPI 등 공개된 API를 사용
- HTTP Get Method
- 정보가 게시되어 있는 대상 웹사이트를 HTTP GET 사용하여 html 코드를 얻고 Text Pasing 하여 사용. 대부분의 언어로 사용 가능
- Selenium Web Driver
- 웹브라우저 인스턴스를 생성해 실행시킨 후 해당 인스턴스를 컨트롤.
- 웹사이트 테스트 자동화 목적으로 개발됨.
- 가상의 브라우저를 실행시키는 Headless Mode 등이 있음
- HTTP Get 방식에 비해 느리고 불안정하다 보다 많은 웹사이트 스크래핑 가능

:bulb: 웹 크롤러 vs 웹 스크래퍼

- 웹 크롤러 (Web Crawler) : 조직적, 자동화된 방법으로 웹을 탐색/수집하는 프로그램. 여러 사이트에서 필요한 데이터를 갖고 오는 봇(Bot)
- 웹 스크래퍼 (Web Scrapper) : 웹사이트에서 필요한 정보를 갖고 오는 프로그램. 고정된 형상에서 데이터를 갖고 오는 방식

:bulb: Q. 크롤링은 불법인가?

A. 웹사이트의 홈디렉토리에 위치한 robots.txt 파일을 열어보고 **해당 사이트의 정책을 준수하지 않는다면** 불법!

A. 크롤링한 자료를 **상업적인 용도로 사용**하면 불법! A. 비상업적인 용도라도 **원작자에게 불이익/Abusing** 시 불법! 

:bulb: Q&A 정리

- 학습 목적, 비공개적 자료로 구성된 크롤링 결과의 경우 크게 법적 문제는 없을 것으로 보임.
- 크롤링 횟수가 많아지면 트래픽에 부담이 가는 경우. 예를 들어 데이터를 연속적으로 가져갈 때(ex. 3초에 한번씩)의 경우 트래픽 높아질 확률이 높기 때문에, 불법적인 예시 중 하나로 IP를 바꿔가며 스크래핑하는 경우도 있습니다. 대체로 부하를 분산시키는 방법으로 처리합니다.